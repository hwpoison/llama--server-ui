# llama.cpp Playground ðŸ¦™

A Playground based on server.cpp from llama.cpp for use the llama models. Has a WebUI and you can play with prompts connecting with a server.cpp execution.
Also you can use a backend if you want to handle multiple instances of server.cpp (only experimental due to the nature of the project).

More information about server.cpp: https://github.com/ggerganov/llama.cpp/tree/master/examples/server

### Screenshot
 ![Image](https://i.ibb.co/QXB89gK/screenshot.png)
* Supports submit, retry, undo and model parameters modification.

### How to run
```
- Install npm and pip dependences following the readmes
- Execute the llama server standalone or if you want from the backend.
- Run the fronted following the instructions in his README.
- Go to http://localhost:3762/
```